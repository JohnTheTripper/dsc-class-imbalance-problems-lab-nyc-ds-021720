{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance Problems - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "Now that you've gone over some techniques for tuning classification models on imbalanced datasets, it's time to practice those techniques. In this lab, you'll investigate credit card fraud and attempt to tune a model to flag suspicious activity.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Use sampling techniques to address a class imbalance problem within a dataset \n",
    "- Create a visualization of ROC curves and use it to assess a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting credit card fraud\n",
    "\n",
    "\n",
    "The following cell loads all the functions you will be using in this lab. All you need to do is run it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pandas to load the compressed CSV file, `'creditcard.csv.gz'`. \n",
    "\n",
    "> Note: You need to pass an additional argument (`compression='gzip'`) to read_csv() in order to load compressed CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a compressed csv file\n",
    "df = pd.read_csv('creditcard.csv.gz', compression='gzip')\n",
    "\n",
    "# Print the first five rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the class imbalance\n",
    "\n",
    "Did you notice that the dataset has 31 columns? The first is a time field followed by columns V1 - V28, created by way of manual feature engineering done on the backend that we have little information about. Finally, there's the amount of the purchase and a binary `'Class'` flag. This last column, `'Class'`, is the indication of whether or not the purchase was fraudulent, and it is what you should be attempting to predict.\n",
    "\n",
    "Take a look at how imbalanced this dataset is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of fraudulent/infraudulent purchases\n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the predictor and target variables\n",
    "\n",
    "Define `X` and `y` and perform a standard train-test split. Assign 25% to the test set and `random_state` to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "y = df['Class']\n",
    "X = df.drop('Class', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the class imbalance in the training and test sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    213233\n",
      "1       372\n",
      "Name: Class, dtype: int64\n",
      "0    0.998258\n",
      "1    0.001742\n",
      "Name: Class, dtype: float64\n",
      "\n",
      "\n",
      "0    71082\n",
      "1      120\n",
      "Name: Class, dtype: int64\n",
      "0    0.998315\n",
      "1    0.001685\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "print(y_train.value_counts())\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print('\\n')\n",
    "# Test set\n",
    "print(y_test.value_counts())\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an initial model\n",
    "\n",
    "As a baseline, train a vanilla logistic regression model. Then plot the ROC curve and print out the AUC. We'll use this as a comparison for how our future models perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Model\n",
    "logreg = LogisticRegression(fit_intercept=False, C = 1e15, solver = 'liblinear')\n",
    "\n",
    "# Probability scores for test set\n",
    "y_score = logreg.fit(X_train, y_train).decision_function(X_test)\n",
    "# False positive rate and true positive rate\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "# Seaborn's beautiful styling\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "\n",
    "# Print AUC\n",
    "print(auc(fpr, tpr))\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function to plot a confusion matrix you defined in an earlier lesson. Use it to plot the confusion matrix of the test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized confusion matrix')\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71026,    56],\n",
       "       [   53,    67]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot confusion matrix of the test set \n",
    "y_hat_test = logreg.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test, y_hat_test)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[71026    56]\n",
      " [   53    67]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrix, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the model \n",
    "\n",
    "Try some of the various techniques proposed to tune your model. Compare your models using AUC and ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's compare a few different regularization performances on the dataset:\n",
    "C_param_range = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "names = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "colors = sns.color_palette('Set2')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for n, c in enumerate(C_param_range):\n",
    "    # Fit a model\n",
    "    logreg = None\n",
    "    model_log = None\n",
    "    print(model_log) # Preview model params\n",
    "\n",
    "    # Predict\n",
    "    y_hat_test = None\n",
    "\n",
    "    y_score = None\n",
    "\n",
    "    fpr, tpr, thresholds = None\n",
    "    \n",
    "    print('AUC for {}: {}'.format(names[n], auc(fpr, tpr)))\n",
    "    print('-------------------------------------------------------')\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color=colors[n],\n",
    "             lw=lw, label='ROC curve Normalization Weight: {}'.format(names[n]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "\n",
    "Use the `SMOTE` class from the `imblearn` package in order to improve the model's performance on the minority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous original class distribution\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Fit SMOTE to training data\n",
    "X_train_resampled, y_train_resampled = None\n",
    "\n",
    "# Preview synthetic sample class distribution\n",
    "print('\\n')\n",
    "print(pd.Series(y_train_resampled).value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what you did above, build models with this resampled training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's compare a few different regularization performances on the dataset\n",
    "C_param_range = [0.005, 0.1, 0.2, 0.5, 0.8, 1, 1.25, 1.5, 2]\n",
    "names = [0.005, 0.1, 0.2, 0.5, 0.8, 1, 1.25, 1.5, 2]\n",
    "colors = sns.color_palette('Set2', n_colors=len(names))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Write a for loop that builds models for each value of C_param_range, prints the AUC and plots the ROC\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something wrong here? \n",
    "Describe what is misleading about the AUC score and ROC curves produced by this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous original class distribution\n",
    "print(y.value_counts()) \n",
    "X_resampled, y_resampled = SMOTE().fit_sample(X, y) \n",
    "# Preview synthetic sample class distribution\n",
    "print('---------------------------------')\n",
    "print(pd.Series(y_resampled).value_counts()) \n",
    "\n",
    "# Split resampled data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=0)\n",
    "\n",
    "# Now let's compare a few different regularization performances on the dataset:\n",
    "C_param_range = [0.005, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8]\n",
    "names = [0.005, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "colors = sns.color_palette('Set2', n_colors=len(names))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for n, c in enumerate(C_param_range):\n",
    "    # Fit a model\n",
    "    logreg = LogisticRegression(fit_intercept=False, C=c, solver='liblinear')\n",
    "    model_log = logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_hat_test = logreg.predict(X_test)\n",
    "\n",
    "    y_score = logreg.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    print('----------------------------------------------')\n",
    "    print('AUC for {}: {}'.format(names[n], auc(fpr, tpr)))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color=colors[n],\n",
    "             lw=lw, label='ROC curve Normalization Weight: {}'.format(names[n]))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you got some hands-on practice tuning logistic regression models. In the upcoming labs and lessons, you will continue to dig into the underlying mathematics of logistic regression, taking on a statistical point of view and providing you with a deeper understanding of how the algorithm works. This should give you further insight as to how to tune and apply these models going forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
